sum(Direction="Up")length(Direction)
sum(Direction="Up")/length(Direction)
sum(Direction=="Up")/length(Direction)
106/(106+76)
train=(Year<2005)
Smarket2005=Smarket[!train,]
dim(Smarket2005)
length(Smarket2005)
dim(Smarket2005)[1]
train=(Year<2005)
Smarket2005=Smarket[!train,]
dim(Smarket2005)
Direction2005=Direction[!train]
model2=glm(Direction~Lag1+Lag2+Lag3+Lag4+Lag5+Volume,data=Smarket,family=binomial,subset=train)
summary(model2)
model2Prob=predict(model2,Smarket2005,type="response")
model2Pred=rep("Down",dim(Smarket2005)[1])
model2Pred[model2Prob>0.5]="Up"
table(model2Pred,Direction2005)
mean(model2Pred==Direction2005)
mean(model2Pred!=Direction2005)
Direction2005
table(Direction2005)
sum(Direction2005=="Up")/length(Direction2005)
model3=glm(Direction~Lag1+Lag2,data=Smarket,family=binomial,subset=train)
summary(model3)
model4=glm(Direction~Lag1,data=Smarket,family=binomial,subset=train)
summary(model4)
model4=glm(Direction~Lag2,data=Smarket,family=binomial,subset=train)
summary(model4)
model4=glm(Direction~Lag3,data=Smarket,family=binomial,subset=train)
summary(model4)
model4=glm(Direction~Lag4,data=Smarket,family=binomial,subset=train)
summary(model4)
model4=glm(Direction~Lag5,data=Smarket,family=binomial,subset=train)
summary(model4)
model4=glm(Direction~Volume,data=Smarket,family=binomial,subset=train)
summary(model4)
model3=glm(Direction~Lag1+Lag2,data=Smarket,family=binomial,subset=train)
summary(model3)
model3Prob=predict(glm.fits,Smarket2005,type="response")
model3Pred=rep("Down",dim(Smarket2005)[1])
model3Pred[model3Prob>0.5]="Up"
model3=glm(Direction~Lag1+Lag2,data=Smarket,family=binomial,subset=train)
summary(model3)
model3Prob=predict(glm.fits,Smarket2005,type="response")
model3Prob=predict(model3,Smarket2005,type="response")
model3Pred=rep("Down",dim(Smarket2005)[1])
model3Pred[model3Prob>0.5]="Up"
table(model3Pred,Direction2005)
mean(model3Pred==Direction2005)
106/(106+76)
sum(Direction2005=="Up")/length(Direction2005)
table(Direction2005)
dataM=read.csv("Data\\Cars_raw_M.csv",sep = ";")
dataM
model3=glm(Direction~Lag1+Lag2,data=Smarket,family=multinomial,subset=train)
bi
rm(list=ls())                    ### Logistic regression ###
library(ISLR)
?Default
str(Default)
?Default
edit(Default)
logitModel=glm(default~balance,data=Default)
logitModel=glm(default~balance,data=Default,family = binomial)
summary(logitModel)
modelProb=predict(logitModel,type="response")
modelProb
logitModel=glm(default~balance,data=Default,family=binomial)
summary(logitModel)
modelProb=predict(logitModel,type="response")
contrasts(Default$default)
contrasts(Default$default)
modelProb
str(Default)
modelPred=rep("No",10000)
modelPred[modelProb>0.5]="Yes"
table(modelPred,Default$default)
rm(list=ls())                    ### Logistic regression ###
library("MASS")
lda.fit=lda(Direction~Lag1+Lag2,data=Smarket,subset=train)
attach(Smarket)
train=(Year<2005)
Smarket2005=Smarket[!train,]
dim(Smarket2005)
Direction2005=Direction[!train]
attach(Smarket)
str(Smarket)
library("MASS")
library(ISLR)
attach(Smarket)
train=(Year<2005)
Smarket2005=Smarket[!train,]
dim(Smarket2005)
Direction2005=Direction[!train]
lda.fit=lda(Direction~Lag1+Lag2,data=Smarket,subset=train)
lda.fit
lda.fit=lda(Direction~Lag1+Lag2,data=Smarket,subset=train)
lda.fit
summary(lda_model)
lda_model=lda(Direction~Lag1+Lag2,data=Smarket,subset=train)
lda_model
summary(lda_model)
plot(lda_model)
rm(list=ls())                       ### Linear Discriminant Analysis ###
attach(Smarket)
train=(Year<2005)
Smarket2005=Smarket[!train,]
Direction2005=Direction[!train]
ldaModel=lda(Direction~Lag1+Lag2,data=Smarket,subset=train)
ldaModel
summary(ldaModel)
plot(ldaModel)
ldaPred=predict(ldaModel, Smarket.2005)
ldaPred=predict(ldaModel, Smarket2005)
names(ldaPred)
ldaClass=ldaPred$class
ldaClass
names(ldaPred)
str(ldaPred)
table(ldaClass,Direction2005)
mean(ldaClass==Direction2005)
sum(ldaPred$posterior[,1]>=.5)
sum(ldaPred$posterior[,1]<.5)
ldaPred$posterior[1:20,1]
sum(ldaPred$posterior[,1]>.9)
sum(ldaPred$posterior[,1]>.8)
sum(ldaPred$posterior[,1]>.7)
summary(ldaPred$posterior)
edit(ldaPred)
ldaPred=predict(ldaModel, Smarket2005)
table(ldaClass,Direction2005)
plot(ldaModel)
scatterplot(ldaModel)
detach(Smarket)
rm(list=ls())                       ### Linear Discriminant Analysis ###
set.seed(357)
Ng <- 100 # number of cases per group
group.a.x <- rnorm(n = Ng, mean = 2, sd = 3)
group.a.y <- rnorm(n = Ng, mean = 2, sd = 3)
group.b.x <- rnorm(n = Ng, mean = 11, sd = 3)
group.b.y <- rnorm(n = Ng, mean = 11, sd = 3)
group.a <- data.frame(x = group.a.x, y = group.a.y, group = "A")
group.b <- data.frame(x = group.b.x, y = group.b.y, group = "B")
my.xy <- rbind(group.a, group.b)
# construct the model
mdl <- lda(group ~ x + y, data = my.xy)
np <- 300
nd.x <- seq(from = min(my.xy$x), to = max(my.xy$x), length.out = np)
nd.y <- seq(from = min(my.xy$y), to = max(my.xy$y), length.out = np)
nd <- expand.grid(x = nd.x, y = nd.y)
prd <- as.numeric(predict(mdl, newdata = nd)$class)
plot(my.xy[, 1:2], col = my.xy$group)
points(mdl$means, pch = "+", cex = 3, col = c("black", "red"))
contour(x = nd.x, y = nd.y, z = matrix(prd, nrow = np, ncol = np),
levels = c(1, 2), add = TRUE, drawlabels = FALSE)
my.xy
Direction
plot(x=Lag1,y=Lag2, col = Direction)
points(ldaModel$means, pch = "+", cex = 3, col = c("black", "red"))
ldaModel=lda(Direction~Lag1+Lag2,data=Smarket,subset=train)
points(ldaModel$means, pch = "+", cex = 3, col = c("black", "red"))
attach(Smarket)
train=(Year<2005)
Smarket2005=Smarket[!train,]
Direction2005=Direction[!train]
ldaModel=lda(Direction~Lag1+Lag2,data=Smarket,subset=train)
points(ldaModel$means, pch = "+", cex = 3, col = c("black", "red"))
prd
contour(x = nd.x, y = nd.y,
levels = c(1, 2), add = TRUE, drawlabels = FALSE)
rm(list=ls())                       ### Linear Discriminant Analysis ###
mydata <- structure(list(Group = c("a", "a", "a", "a", "a", "a", "a", "a",
"b", "b", "b", "b", "b", "b", "b", "b", "c", "c", "c", "c", "c",
"c", "c", "c"), Var1 = c(7.5, 6.9, 6.5, 7.3, 8.1, 8, 7.4, 7.8,
8.3, 8.7, 8.9, 9.3, 8.5, 9.6, 9.8, 9.7, 11.2, 10.9, 11.5, 12,
11, 11.6, 11.7, 11.3), Var2 = c(-6.5, -6.2, -6.7, -6.9, -7.1,
-8, -6.5, -6.3, -9.3, -9.5, -9.6, -9.1, -8.9, -8.7, -9.9, -10,
-6.7, -6.4, -6.8, -6.1, -7.1, -8, -6.9, -6.6)), .Names = c("Group",
"Var1", "Var2"), class = "data.frame", row.names = c(NA, -24L
))
np <- 300
nd.x = seq(from = min(mydata$Var1), to = max(mydata$Var1), length.out = np)
nd.y = seq(from = min(mydata$Var2), to = max(mydata$Var2), length.out = np)
nd = expand.grid(Var1 = nd.x, Var2 = nd.y)
new.lda = lda(Group ~ Var1 + Var2, data=mydata)
prd = as.numeric(predict(new.lda, newdata = nd)$class)
p = predict(new.lda, newdata= nd)
p.x = seq(from = min(p$x[,1]), to = max(p$x[,1]), length.out = np) #LD1 scores
p.y = seq(from = min(p$x[,2]), to = max(p$x[,2]), length.out = np) #LD2 scores
plot(new.lda, panel = function(x, y, ...) { points(x, y, ...) },
col = c(4,2,3)[factor(mydata$Group)],
pch = c(17,19,15)[factor(mydata$Group)],
ylim=c(-3,3), xlim=c(-5,5))
contour(x = p.x, y = p.y, z = matrix(prd, nrow = np, ncol = np),
levels = c(1, 2, 3), add = TRUE, drawlabels = FALSE)
np <- 3000
nd.x = seq(from = min(mydata$Var1), to = max(mydata$Var1), length.out = np)
nd.y = seq(from = min(mydata$Var2), to = max(mydata$Var2), length.out = np)
nd = expand.grid(Var1 = nd.x, Var2 = nd.y)
new.lda = lda(Group ~ Var1 + Var2, data=mydata)
prd = as.numeric(predict(new.lda, newdata = nd)$class)
np <- 3000
nd.x = seq(from = min(mydata$Var1), to = max(mydata$Var1), length.out = np)
nd.y = seq(from = min(mydata$Var2), to = max(mydata$Var2), length.out = np)
nd = expand.grid(Var1 = nd.x, Var2 = nd.y)
new.lda = lda(Group ~ Var1 + Var2, data=mydata)
library("MASS")
new.lda = lda(Group ~ Var1 + Var2, data=mydata)
prd = as.numeric(predict(new.lda, newdata = nd)$class)
str(ldaPred2005)
rm(list=ls())                       ### Linear Discriminant Analysis ###
attach(Smarket)
library(ISLR)
attach(Smarket)
train=(Year<2005)
Smarket2005=Smarket[!train,]
Direction2005=Direction[!train]
ldaModel=lda(Direction~Lag1+Lag2,data=Smarket,subset=train)
ldaModel
library("MASS")
ldaModel=lda(Direction~Lag1+Lag2,data=Smarket,subset=train)
ldaModel
summary(ldaModel)
plot(ldaModel)
plot(x=Lag1,y=Lag2, col = Direction)
points(ldaModel$means, pch = "+", cex = 3, col = c("black", "red"))
ldaPred=predict(ldaModel, Smarket[train,])
ldaClass=ldaPred$class
ldaClass
table(ldaClass,Direction[train])
ldaPred
ldaPred$class
str(ldaPred2005)
ldaPred2005=predict(ldaModel, Smarket2005)
names(ldaPred2005)
str(ldaPred2005)
edit(ldaPred)
ldaPred2005$x
ldaPred2005
ldaPred2005
rm(list=ls())                       ### Linear Discriminant Analysis ###
library("MASS")
set.seed(1)
groupN <- 100 # number of cases per group
group1x <- rnorm(n = groupN, mean = 2, sd = 3)
group1y <- rnorm(n = groupN, mean = 2, sd = 3)
group2x <- rnorm(n = groupN, mean = 11, sd = 3)
group2y <- rnorm(n = groupN, mean = 11, sd = 3)
group1 <- data.frame(x = group1x, y = group1y, group = "A")
group2 <- data.frame(x = group2x, y = group2y, group = "B")
simData <- rbind(group1, group2)
simData
rm(list=ls())                       ### Linear Discriminant Analysis ###
library("MASS")
set.seed(1)
groupN=100 # number of cases per group
group1x=rnorm(n = groupN, mean = 2, sd = 3)
group1y=rnorm(n = groupN, mean = 2, sd = 3)
group2x=rnorm(n = groupN, mean = 11, sd = 3)
group2y=rnorm(n = groupN, mean = 11, sd = 3)
group1=data.frame(x = group1x, y = group1y, group = "A")
group2=data.frame(x = group2x, y = group2y, group = "B")
simData=rbind(group1, group2)
simModel=lda(group ~ x + y, data = simData)
simModel
plot(simModel)
plot(simData[, 1:2], col = simData[,3])
points(simModel$means, pch = "+", cex = 3, col = c("black", "red"))
set.seed(1)
groupN=100 # number of cases per group
group1x=rnorm(n = groupN, mean = 0, sd = 5)
group1y=rnorm(n = groupN, mean = 0, sd = 5)
group2x=rnorm(n = groupN, mean = 10, sd = 7)
group2y=rnorm(n = groupN, mean = 10, sd = 7)
group2=data.frame(x = group2x, y = group2y, group = "B")
group1=data.frame(x = group1x, y = group1y, group = "A")
simData=rbind(group1, group2)
simModel=lda(group ~ x + y, data = simData)
simModel
plot(simModel)
plot(simData[, 1:2], col = simData[,3])
points(simModel$means, pch = "+", cex = 3, col = c("black", "red"))
set.seed(1)
groupN=100 # number of cases per group
group1x=rnorm(n = groupN, mean = 0, sd = 4)
group1y=rnorm(n = groupN, mean = 0, sd = 4)
group2y=rnorm(n = groupN, mean = 10, sd = 5)
group2x=rnorm(n = groupN, mean = 10, sd = 5)
group1=data.frame(x = group1x, y = group1y, group = "A")
group2=data.frame(x = group2x, y = group2y, group = "B")
simData=rbind(group1, group2)
simModel=lda(group ~ x + y, data = simData)
simModel
plot(simModel)
plot(simData[, 1:2], col = simData[,3])
points(simModel$means, pch = "+", cex = 3, col = c("black", "red"))
rm(list=ls())                       ### Linear Discriminant Analysis ###
library("MASS")
set.seed(1)
groupN=100 # number of cases per group
group1x=rnorm(n = groupN, mean = 0, sd = 4)
group1y=rnorm(n = groupN, mean = 0, sd = 4)
group2x=rnorm(n = groupN, mean = 10, sd = 5)
group2y=rnorm(n = groupN, mean = 10, sd = 5)
group1=data.frame(x = group1x, y = group1y, group = "A")
group2=data.frame(x = group2x, y = group2y, group = "B")
simData=rbind(group1, group2)
simModel=lda(group ~ x + y, data = simData)
simModel
plot(simModel)
plot(simData[,1:2], col = simData[,3])
points(simModel$means, pch = "+", cex = 3, col = c("black", "red"))
predN=100
newDataX <- seq(from = min(simData$x), to = max(simData$x), length.out = predN)
newDataY <- seq(from = min(simData$y), to = max(simData$y), length.out = predN)
newData <- expand.grid(x = newDataX, y = newDataY)
predData <- as.numeric(predict(simModel, newdata = newData)$class)
contour(x = newDataX, y = newDataY, z = matrix(predData, nrow = predN, ncol = predN),
levels = c(1, 2), add = TRUE, drawlabels = FALSE)
predN=300
newDataX <- seq(from = min(simData$x), to = max(simData$x), length.out = predN)
newDataY <- seq(from = min(simData$y), to = max(simData$y), length.out = predN)
newData <- expand.grid(x = newDataX, y = newDataY)
predData <- as.numeric(predict(simModel, newdata = newData)$class)
contour(x = newDataX, y = newDataY, z = matrix(predData, nrow = predN, ncol = predN),
levels = c(1, 2), add = TRUE, drawlabels = FALSE)
library(ISLR)
predN=1000
newDataX <- seq(from = min(simData$x), to = max(simData$x), length.out = predN)
newDataY <- seq(from = min(simData$y), to = max(simData$y), length.out = predN)
newData <- expand.grid(x = newDataX, y = newDataY)
predData <- as.numeric(predict(simModel, newdata = newData)$class)
contour(x = newDataX, y = newDataY, z = matrix(predData, nrow = predN, ncol = predN),
levels = c(1, 2), add = TRUE, drawlabels = FALSE)
plot(simData[,1:2], col = simData[,3])
points(simModel$means, pch = "+", cex = 3, col = c("black", "red"))
predN=1000
newDataX <- seq(from = min(simData$x), to = max(simData$x), length.out = predN)
newDataY <- seq(from = min(simData$y), to = max(simData$y), length.out = predN)
newData <- expand.grid(x = newDataX, y = newDataY)
predData <- as.numeric(predict(simModel, newdata = newData)$class)
contour(x = newDataX, y = newDataY, z = matrix(predData, nrow = predN, ncol = predN),
levels = c(1, 2), add = TRUE, drawlabels = FALSE)
data("iris")
str(iris)
boxplot(iris)
boxplot(iris~Spacies)
boxplot(iris~Species)
boxplot(iris[,1:4]~Species)
boxplot(iris[,1:4]~iris$Species)
boxplot(iris$Species~iris[,1:4])
boxplot(iris[,1:4])
boxplot(iris[which(iris$Species==1),1:4])
which(iris$Species==1)
str(iris)
boxplot(iris[which(iris$Species=="setosa"),1:4])
iris$Species
str(iris)
boxplot(iris[which(iris$Species=="setosa"),1:4])
boxplot(iris[which(iris$Species=="versicolor"),1:4])
boxplot(iris[which(iris$Species=="virginica"),1:4])
mydata <- structure(list(Group = c("a", "a", "a", "a", "a", "a", "a", "a",
"b", "b", "b", "b", "b", "b", "b", "b", "c", "c", "c", "c", "c",
"c", "c", "c"), Var1 = c(7.5, 6.9, 6.5, 7.3, 8.1, 8, 7.4, 7.8,
8.3, 8.7, 8.9, 9.3, 8.5, 9.6, 9.8, 9.7, 11.2, 10.9, 11.5, 12,
11, 11.6, 11.7, 11.3), Var2 = c(-6.5, -6.2, -6.7, -6.9, -7.1,
-8, -6.5, -6.3, -9.3, -9.5, -9.6, -9.1, -8.9, -8.7, -9.9, -10,
-6.7, -6.4, -6.8, -6.1, -7.1, -8, -6.9, -6.6)), .Names = c("Group",
"Var1", "Var2"), class = "data.frame", row.names = c(NA, -24L
))
boxplot(iris[which(iris$Species=="setosa"),1:4])
boxplot(iris[which(iris$Species=="versicolor"),1:4])
boxplot(iris[which(iris$Species=="virginica"),1:4])
boxplot(iris[which(iris$Species=="setosa"),1:4])
boxplot(iris[which(iris$Species=="versicolor"),1:4])
boxplot(iris[which(iris$Species=="virginica"),1:4])
model=lda(Species~.,data=iris)
model
model2=lda(Species~Sepal.Length+Sepal.Width,data=iris)
model2
plot(x=iris$Sepal.Length,iris$Sepal.Width, col = iris$Species)
points(model2$means, pch = "+", cex = 3, col = c(1,2,3))
predN=1000
newDataX <- seq(from = min(iris$Sepal.Length), to = max(iris$Sepal.Length), length.out = predN)
newDataY <- seq(from = min(iris$Sepal.Width), to = max(iris$Sepal.Width), length.out = predN)
newData <- expand.grid(x = newDataX, y = newDataY)
predData <- as.numeric(predict(model2, newdata = newData)$class)
iris$Sepal.Width
model2
predData <- as.numeric(predict(model2, newdata = newData)$class)
newDataX <- seq(from = min(iris$Sepal.Length), to = max(iris$Sepal.Length), length.out = predN)
newDataY <- seq(from = min(iris$Sepal.Width), to = max(iris$Sepal.Width), length.out = predN)
newData <- expand.grid(Sepal.Length = newDataX, Sepal.Width = newDataY)
predData <- as.numeric(predict(model2, newdata = newData)$class)
contour(x = newDataX, y = newDataY, z = matrix(predData, nrow = predN, ncol = predN),
levels = c(1,2,3), add = TRUE, drawlabels = FALSE)
rm(list=ls())                       ### Linear Discriminant Analysis ###
rm(list=ls())                       ### Linear Discriminant Analysis ###
# Simulated example of LDA #
# install.packages("MASS")
library("MASS")
# generate data
set.seed(1)
groupN=100 # number of cases per group
group1x=rnorm(n = groupN, mean = 0, sd = 4)
group1y=rnorm(n = groupN, mean = 0, sd = 4)
group2x=rnorm(n = groupN, mean = 10, sd = 5)
group2y=rnorm(n = groupN, mean = 10, sd = 5)
group1=data.frame(x = group1x, y = group1y, group = "A")
group2=data.frame(x = group2x, y = group2y, group = "B")
simData=rbind(group1, group2)
# LDA
simModel=lda(group ~ x + y, data = simData)
simModel
plot(simModel)
# The Stock Market Data #
# install.packages("ISLR")
library(ISLR)
str(Smarket)
?Smarket
edit(Smarket)
str(Smarket)
?Smarket
edit(Smarket)
summary(Smarket)
plot(Smarket)
cor(Smarket) # WRONG! -> Factor variable
cor(Smarket[,-9])
plot(Smarket$Volume)
plot(Smarket$Volume)
attach(Smarket)
train=(Year<2005)
Smarket2005=Smarket[!train,]
Direction2005=Direction[!train]
ldaModel=lda(Direction~Lag1+Lag2,data=Smarket,subset=train)
ldaModel
summary(ldaModel)
plot(ldaModel)
### IRIS dataset ###
# install.packages("MASS")
library("MASS")
data("iris")
str(iris)
library("ISLR")
data("Default")
Default$student = as.numeric(Default$student)
Default$default = as.numeric(Default$default)
View(Default)
plot(default~student,data=Default)
plot(default~balance,data=Default)
smp_size <- floor(0.75 * nrow(Default))
train_ind <- sample(seq_len(nrow(Default)), size = smp_size)
smp_size <- floor(0.9 * nrow(Default))
train_ind <- sample(seq_len(nrow(Default)), size = smp_size)
df_train = Default[train_ind,]
df_test = Default[-train_ind,]
cor(Default)
lda_model_1 = lda(default~student+balance+income, data=df_train)
lda_model_no_income = lda(default~student+balance, data=df_train)
?shapiro.test
df_train$default=1
# corelaciqta e dobra mqrka za neprekusnati
df_train_1 = df_train[df_train$default==1,]
df_train$default==1
df_train = Default[train_ind,]
df_train = Default[train_ind,]
df_test = Default[-train_ind,]
# ne e dobra praktika
cor(Default)
df_train$default==1
df_train_1 = df_train[df_train$default==1,]
df_train_1
shapiro.test(balance, data=df_train_1)
shapiro.test(df_train$balance)
shapiro.test(df_train_1$balance)
shapiro.test(df_train_1$balance)
df_train_1.size()
size(df_train_1)
length(df_train_1)
str(df_train_1)
df_train_2 = df_train[df_train$default==2,]
str(df_train_2)
shapiro.test(df_train_2$balance)
ks.test(df_train_1$balance, "pnorm")
ks.test(df_train_1$balance, "norm")
?ks.test
ks.test(df_train_1$balance, "pnorm", mean(df_train_1$balance), sd(df_train_1$balance))
shapiro.test(df_train_2$balance)
train_ind <- sample(seq_len(nrow(Default)), size = smp_size)
shapiro.test(df_train_2$balance)
lda_model_1 = lda(default~student+balance+income, data=df_train)
library(MASS)
# VAPROS: Kak opredelqme koi feature-i sa vajni i koi ne sa?
lda_model_1 = lda(default~student+balance+income, data=df_train)
summary(lda_model_1)
lda_model_1
lda_model_no_income = lda(default~student+balance, data=df_train)
lda_model_no_student = lda(default~income+balance, data=df_train)
lda_model_no_student
plot(x=df_train$student, y=df_train$balance, col=df_train$default)
points(lda_model_no_income$means, pch = "+", cex = 3, col = c(1,2,3))
plot(x=df_train$income, y=df_train$balance, col=df_train$default)
points(lda_model_no_income$means, pch = "+", cex = 3, col = c(1,2,3))
points(lda_model_no_student$means, pch = "+", cex = 3, col = c(1,2,3))
points(lda_model_no_student$means, pch = "+", cex = 2, col = c(3,4))
#Make predictions fore train set
train_predict = predict(lda_model_no_income, df_train)
#Make predictions fore test set
test_predict_no_income=predict(lda_model_no_income, df_test)
test_predict_no_student=predict(lda_model_no_student, df_test)
