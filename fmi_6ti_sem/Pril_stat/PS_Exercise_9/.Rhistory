}
bartlett_p.value
if(bartlett_stat>1){
bartlett_p.value=pf(bartlett_stat, df.residual(lmg1), df.residual(lmg2), lower.tail = FALSE)
}
if(bartlett_stat>1){
bartlett_p.value=pf(bartlett_stat, df.residual(lmg1), df.residual(lmg2), lower.tail = FALSE)
} else{
bartlett_p.value=pf(1/bartlett_stat, df.residual(lmg2), df.residual(lmg1), lower.tail = FALSE)}
c("Stat"=bartlett_stat,"p.value"=bartlett_p.value)
set.seed (1)
x1=runif (100)
x2=0.5*x1+rnorm(100)/10
y=2+2*x1 +0.3*x2+rnorm(100)
y
lm(y~x1+x2)
summary(lm(y~x1+x2))
plot(x1,x2)
summary(lm(y~x1+x2))
cor.test(x1,x2)
summary(lm(y~x1))
summary(lm(y~x2))
summary(lm(y~x1+x2))
rm(list=ls())
library(readxl)
read_excel("Data\\Cars_raw.xls",sheet=1)
dataM=as.data.frame(read_excel("Data\\Cars_raw.xls",sheet=2)) # data for modelling
corTable=cor(dataM)
corTable
model2=lm(Y~X2+X4,data = dataM)
summary(model2)
corTable
QMC_X10=lm(X10~X2+X4,data = dataM)
summary(QMC_X10)
model3=lm(Y~X2+X4+X10,data = dataM)
summary(model3)
corTable
QMC_X1=lm(X1~X2+X4+X10,data = dataM)
summary(QMC_X1)
model4=lm(Y~X2+X4+X10+X1,data = dataM)
summary(model4)
corTable
QMC_X3=lm(X3~X2+X4+X10,data = dataM)
summary(QMC_X3)
model5=lm(Y~X2+X4+X10+X3,data = dataM)
summary(model5)
corTable
QMC_X5=lm(X5~X2+X4+X10+X3,data = dataM)
summary(QMC_X5)
model6=lm(Y~X2+X4+X10+X3+X5,data = dataM)
summary(model6)
corTable
QMC_X8=lm(X8~X2+X4+X10+X3+X5,data = dataM)
summary(QMC_X8)
QMC_X8=lm(X8~X2+X4+X10+X3+X5,data = dataM)
summary(QMC_X8)
model7=lm(Y~X2+X4+X10+X3+X5+X8,data = dataM)
summary(model7)
corTable
summary(QMC_X1)
summary(model4)
corTable
QMC_X7=lm(X7~X2+X4+X10+X3+X5,data = dataM)
summary(QMC_X7)
corTable
QMC_X9=lm(X9~X2+X4+X10+X3+X5,data = dataM)
summary(QMC_X9)
model8=lm(Y~X2+X4+X10+X3+X5+X9,data = dataM)
summary(model8)
QMC_X6=lm(X6~X2+X4+X10+X3+X5+X9,data = dataM)
summary(QMC_X6)
model9=lm(Y~X2+X4+X10+X3+X5+X9+X6,data = dataM)
summary(model9)
model=lm(Y~X2+X4+X10+X3+X5+X9,data = dataM)
summary(model)
rm(list=ls())
dataM=read.csv("Data\\Cars_raw_M.csv",sep = ";")
dataM
dataM=as.data.frame(read_excel("Data\\Cars_raw.xls",sheet=2)) # data for modelling
library(readxl)
read_excel("Data\\Cars_raw.xls",sheet=1)
dataM=as.data.frame(read_excel("Data\\Cars_raw.xls",sheet=2)) # data for modelling
model2=lm(Y~X2+X4,data = dataM)
summary(model2)
QMC_X10=lm(X10~X2+X4,data = dataM)
summary(QMC_X10)
model3=lm(Y~X2+X4+X10,data = dataM)
summary(model3)
QMC_X1=lm(X1~X2+X4+X10,data = dataM)
summary(QMC_X1)
model4=lm(Y~X2+X4+X10+X1,data = dataM)
summary(model4)
QMC_X3=lm(X3~X2+X4+X10,data = dataM)
summary(QMC_X3)
model5=lm(Y~X2+X4+X10+X3,data = dataM)
summary(model5)
QMC_X5=lm(X5~X2+X4+X10+X3,data = dataM)
summary(QMC_X5)
model6=lm(Y~X2+X4+X10+X3+X5,data = dataM)
summary(model6)
QMC_X8=lm(X8~X2+X4+X10+X3+X5,data = dataM)
summary(QMC_X8)
model7=lm(Y~X2+X4+X10+X3+X5+X8,data = dataM)
summary(model7)
QMC_X7=lm(X7~X2+X4+X10+X3+X5,data = dataM)
summary(QMC_X7)
QMC_X9=lm(X9~X2+X4+X10+X3+X5,data = dataM)
summary(QMC_X9)
model8=lm(Y~X2+X4+X10+X3+X5+X9,data = dataM)
summary(model8)
QMC_X6=lm(X6~X2+X4+X10+X3+X5+X9,data = dataM)
summary(QMC_X6)
model9=lm(Y~X2+X4+X10+X3+X5+X9+X6,data = dataM)
summary(model9)
model=lm(Y~X2+X4+X10+X3+X5+X9,data = dataM)
summary(model)
plot(model)
dataP=read.csv("Data\\Cars_raw_P.csv",sep = ";")
dataP
rm(list=ls())                    ### Quasi-multicollinearity ###
library(readxl)
read_excel("Data\\Cars_raw.xls",sheet=1)
dataM=as.data.frame(read_excel("Data\\Cars_raw.xls",sheet=2)) # data for modelling
corTable=cor(dataM)
model2=lm(Y~X2+X4,data = dataM)
summary(model2)
QMC_X10=lm(X10~X2+X4,data = dataM)
summary(QMC_X10)
model3=lm(Y~X2+X4+X10,data = dataM)
summary(model3)
QMC_X1=lm(X1~X2+X4+X10,data = dataM)
summary(QMC_X1)
model4=lm(Y~X2+X4+X10+X1,data = dataM)
summary(model4)
QMC_X3=lm(X3~X2+X4+X10,data = dataM)
summary(QMC_X3)
model5=lm(Y~X2+X4+X10+X3,data = dataM)
summary(model5)
QMC_X5=lm(X5~X2+X4+X10+X3,data = dataM)
summary(QMC_X5)
model6=lm(Y~X2+X4+X10+X3+X5,data = dataM)
summary(model6)
QMC_X8=lm(X8~X2+X4+X10+X3+X5,data = dataM)
summary(QMC_X8)
model7=lm(Y~X2+X4+X10+X3+X5+X8,data = dataM)
summary(model7)
QMC_X7=lm(X7~X2+X4+X10+X3+X5,data = dataM)
summary(QMC_X7)
QMC_X9=lm(X9~X2+X4+X10+X3+X5,data = dataM)
summary(QMC_X9)
model8=lm(Y~X2+X4+X10+X3+X5+X9,data = dataM)
summary(model8)
QMC_X6=lm(X6~X2+X4+X10+X3+X5+X9,data = dataM)
summary(QMC_X6)
model9=lm(Y~X2+X4+X10+X3+X5+X9+X6,data = dataM)
summary(model9)
model=lm(Y~X2+X4+X10+X3+X5+X9,data = dataM)
summary(model)
dataP=as.data.frame(read_excel("Data\\Cars_raw.xls",sheet=3)) # data for modelling
dataP
predict(model, newdata=dataP)
predict(model, int="p", newdata=dataP)
predict(model, int="p", newdata=dataP)
Y_predicted=predict(model, newdata=dataP)
Y_predicted
MAE=mean(abs(dataM$Y-Y_predicted))
MAE=mean(abs(dataP$Y-Y_predicted))
MAE
MSE=mean((dataP$Y-Y_predicted)^2)
MSE
MAE=mean(abs(dataP$Y-Y_predicted))  # Mean Absolute Error
MSE=mean((dataP$Y-Y_predicted)^2)   # Mean Squared Error
RMSE=sqrt(MSE)                      # Root Mean Squared Error
MSE
RMSE
MAE
MARE=mean(abs((dataP$Y-Y_predicted)/dataP$Y))  # Mean Absolute Relative Error
MARE
MSRE=mean(((dataP$Y-Y_predicted)/dataP$Y)^2)  # Mean Squared Relative Error
MSRE
MAE RMSE
MAE; RMSE
c=("MAE"=MAE,"RMSE"=RMSE)
c=("MAE"=MAE;"RMSE"=RMSE)
c=(MAE=MAE,RMSE=RMSE)
c=(MAE=MAE,RMSE=RMSE)
MAE;RMSE
MARE=mean(abs((dataP$Y-Y_predicted)/dataP$Y))  # Mean Absolute Relative Error
MSRE=mean(((dataP$Y-Y_predicted)/dataP$Y)^2)  # Mean Squared Relative Error
RMSRE=sqrt(MSRE)                              # Root Mean Squared Relative Error
MARE; RMSRE
PMAE=MAE/mean(dataP$Y)  # Percentage Mean Absolute Error
PMAE
PMAE; PRMSE
PRMSE=RMSE/mean(dataP$Y)    # Percentage Root Mean Squared Error
PMAE; PRMSE
MARE; RMSRE
cor.test(Y_predicted,dataP$Y)
plot(dataP$Y, Y_predicted, pch=21,cex=1.5,bg=rgb(1/3,1/3,1/3))
plot(Y_predicted, dataP$Y, pch=21,cex=1.5,bg=rgb(1/3,1/3,1/3))
abline(lm(Y_predicted~dataP$Y), col=rgb(220/255,0,0), lwd=3)
plot(dataP$Y, Y_predicted, pch=21,cex=1.5,bg=rgb(1/3,1/3,1/3))
abline(lm(dataP$Y~Y_predicted), col=rgb(220/255,0,0), lwd=3)
summary(lm(dataP$Y~Y_predicted))
plot(dataP$Y, Y_predicted, pch=21,cex=1.5,bg=rgb(1/3,1/3,1/3))
abline(lm(dataP$Y~Y_predicted-1), col=rgb(220/255,0,0), lwd=3)
summary(lm(dataP$Y~Y_predicted-1))
summary(lm(dataP$Y~Y_predicted))
Theil_coeff=sqrt(mean((dataP$Y)^2)+mean((Y_predicted)^2))/sqrt(mean((dataP$Y-Y_predicted)^2))
Theil_coeff
Theil_coeff=sqrt(mean((dataP$Y-Y_predicted)^2))/sqrt(mean((dataP$Y)^2)+mean((Y_predicted)^2))
Theil_coeff
se=sqrt(deviance(model)/df.residual(model))
se                  # standard error
rse=se/mean(dataM$Y)
rse                 # realtive standard error
Advertising=read.csv("Data\\Advertising.csv",sep = ";")
rm(list=ls())
Advertising=read.csv("Data\\Advertising.csv",sep = ";")
Advertising
Advertising=read.csv("Data\\Advertising.csv",sep = ",")
Advertising
Advertising=read.csv("Data\\Advertising.csv",sep = ",",colClasses=c("NULL",NA,NA,NA,NA))
Advertising
str(Advertising)
rm(list=ls())                    ### Quasi-multicollinearity ###
library(readxl)
read_excel("Data\\Cars_raw.xls",sheet=1)
dataM=as.data.frame(read_excel("Data\\Cars_raw.xls",sheet=2)) # data for modelling
model2=lm(Y~X2+X4,data = dataM)
summary(model2)
model2=lm(Y~X2:X4,data = dataM)
summary(model2)
model2=lm(Y~X2*X4,data = dataM)
summary(model2)
model2=lm(Y~X2*X4+X2*X10,data = dataM)
summary(model2)
library(ISLR)
names(Smarket)
dim(Smarket)
summary(Smarket)
str(Smarket)
?Smarket
edit(Smarket)
edit(Smarket)
pairs(Smarket)
cor(Smarket)
cor(Smarket)
cor(Smarket[,-9])
plot(Volume,data=Smarket)
plot(Smarket$Volume)
cor(Smarket)
cor(Smarket[,-9])
glm.fits=glm(Direction~Lag1+Lag2+Lag3+Lag4+Lag5+Volume,data=Smarket,family=binomial)
summary(glm.fits)
summary(Smarket)
summary(glm.fits)
summary(glm.fits)$coef
summary(glm.fits)$coef[,4]
glm.probs=predict(glm.fits,type="response")
glm.probs[1:10]
glm.probs
contrasts(Direction)
attach(Smarket)
contrasts(Direction)
glm.pred=rep("Down",1250)
glm.pred
glm.probs
glm.pred[glm.probs>0.5]="Up"
table(glm.pred,Direction)
Direction
glm.pred
table(glm.pred,Direction)
(507+145)/1250
mean(glm.pred==Direction)
train=(Year<2005)
Smarket.2005=Smarket[!train,]
Smarket.2005
dim(Smarket.2005)
Direction.2005=Direction[!train]
glm.fits=glm(Direction~Lag1+Lag2+Lag3+Lag4+Lag5+Volume,data=Smarket,family=binomial,subset=train)
glm.probs=predict(glm.fits,Smarket.2005,type="response")
glm.pred=rep("Down",252)
glm.pred[glm.probs>0.5]="Up"
table(glm.pred,Direction.2005)
mean(glm.pred==Direction.2005)
mean(glm.pred!=Direction.2005)
glm.fits=glm(Direction~Lag1+Lag2,data=Smarket,family=binomial,subset=train)
glm.probs=predict(glm.fits,Smarket.2005,type="response")
glm.pred=rep("Down",252)
dim(Smarket.2005)
table(glm.pred,Direction.2005)
mean(glm.pred==Direction.2005)
glm.probs=predict(glm.fits,Smarket.2005,type="response")
glm.pred=rep("Down",252)
glm.pred[glm.probs>0.5]="Up"
table(glm.pred,Direction.2005)
mean(glm.pred==Direction.2005)
mean(glm.pred!=Direction.2005)
glm.fits=glm(Direction~Lag1+Lag2,data=Smarket,family=binomial,subset=train)
glm.probs=predict(glm.fits,Smarket.2005,type="response")
glm.pred=rep("Down",252)
glm.pred[glm.probs>.5]="Up"
table(glm.pred,Direction.2005)
mean(glm.pred==Direction.2005)
106/(106+76)
predict(glm.fits,newdata=data.frame(Lag1=c(1.2,1.5),Lag2=c(1.1,-0.8)),type="response")
detach(Smarket)
install.packages("ISLR")
install.packages("ISLR")
plot(Smarket)
pairs(Smarket)
attach(Caravan)
summary(Caravan)
?Caravan
str(Caravan)
summary(Purchase)
summary(Purchase)
348/5822
standardized.X=scale(Caravan[,-86])
scale(Caravan[,-86])
var(Caravan[,1])
var(Caravan[,2])
var(standardized.X[,1])
var(standardized.X[,2])
var(Caravan[,1])
var(Caravan[,2])
var(standardized.X[,1])
var(standardized.X[,2])
train.X=standardized.X[-test,]
test=1:1000
train.X=standardized.X[-test,]
test.X=standardized.X[test,]
train.X=standardized.X[-test,]
train.X
glm.fits=glm(Purchase~.,data=Caravan,family=binomial,subset=-test)
test=1:1000
glm.fits=glm(Purchase~.,data=Caravan,family=binomial,subset=-test)
summary(glm.fits)
glm.probs=predict(glm.fits,Caravan[test,],type="response")
glm.pred=rep("No",1000)
glm.pred[glm.probs>.5]="Yes"
table(glm.pred,test.Y)
standardized.X=scale(Caravan[,-86])
var(Caravan[,1])
var(Caravan[,2])
var(standardized.X[,1])
var(standardized.X[,2])
test=1:1000
train.X=standardized.X[-test,]
test.X=standardized.X[test,]
train.Y=Purchase[-test]
test.Y=Purchase[test]
glm.fits=glm(Purchase~.,data=Caravan,family=binomial,subset=-test)
glm.probs=predict(glm.fits,Caravan[test,],type="response")
glm.pred=rep("No",1000)
glm.pred[glm.probs>.5]="Yes"
table(glm.pred,test.Y)
glm.pred=rep("No",1000)
glm.pred[glm.probs>.25]="Yes"
table(glm.pred,test.Y)
glm.probs
glm.pred
detach(Caravan)
rm(list=ls())                    ### Logistic regression ###
str(Smarket)
attach(Smarket)
model1=glm(Direction~Lag1+Lag2+Lag3+Lag4+Lag5+Volume,data=Smarket,family=binomial)
summary(model1)
coef(model1)
summary(model1)$coef
summary(model1)$coef[,4]
model1Prob=predict(model1,type="response")
model1Prob[1:10]
contrasts(Direction)
model1Pred=rep("Down",1250)
model1Pred[model1Prob>0.5]="Up"
table(model1Pred,Direction)
(507+145)/1250
mean(model1Pred==Direction)
Direction
table(Direction)
(507+145)/1250
648/(602+648)
size(Direction)
length(Direction)
sum(Direction="Up")length(Direction)
sum(Direction="Up")/length(Direction)
sum(Direction=="Up")/length(Direction)
106/(106+76)
train=(Year<2005)
Smarket2005=Smarket[!train,]
dim(Smarket2005)
length(Smarket2005)
dim(Smarket2005)[1]
train=(Year<2005)
Smarket2005=Smarket[!train,]
dim(Smarket2005)
Direction2005=Direction[!train]
model2=glm(Direction~Lag1+Lag2+Lag3+Lag4+Lag5+Volume,data=Smarket,family=binomial,subset=train)
summary(model2)
model2Prob=predict(model2,Smarket2005,type="response")
model2Pred=rep("Down",dim(Smarket2005)[1])
model2Pred[model2Prob>0.5]="Up"
table(model2Pred,Direction2005)
mean(model2Pred==Direction2005)
mean(model2Pred!=Direction2005)
Direction2005
table(Direction2005)
sum(Direction2005=="Up")/length(Direction2005)
model3=glm(Direction~Lag1+Lag2,data=Smarket,family=binomial,subset=train)
summary(model3)
model4=glm(Direction~Lag1,data=Smarket,family=binomial,subset=train)
summary(model4)
model4=glm(Direction~Lag2,data=Smarket,family=binomial,subset=train)
summary(model4)
model4=glm(Direction~Lag3,data=Smarket,family=binomial,subset=train)
summary(model4)
model4=glm(Direction~Lag4,data=Smarket,family=binomial,subset=train)
summary(model4)
model4=glm(Direction~Lag5,data=Smarket,family=binomial,subset=train)
summary(model4)
model4=glm(Direction~Volume,data=Smarket,family=binomial,subset=train)
summary(model4)
model3=glm(Direction~Lag1+Lag2,data=Smarket,family=binomial,subset=train)
summary(model3)
model3Prob=predict(glm.fits,Smarket2005,type="response")
model3Pred=rep("Down",dim(Smarket2005)[1])
model3Pred[model3Prob>0.5]="Up"
model3=glm(Direction~Lag1+Lag2,data=Smarket,family=binomial,subset=train)
summary(model3)
model3Prob=predict(glm.fits,Smarket2005,type="response")
model3Prob=predict(model3,Smarket2005,type="response")
model3Pred=rep("Down",dim(Smarket2005)[1])
model3Pred[model3Prob>0.5]="Up"
table(model3Pred,Direction2005)
mean(model3Pred==Direction2005)
106/(106+76)
sum(Direction2005=="Up")/length(Direction2005)
table(Direction2005)
dataM=read.csv("Data\\Cars_raw_M.csv",sep = ";")
dataM
model3=glm(Direction~Lag1+Lag2,data=Smarket,family=multinomial,subset=train)
bi
rm(list=ls())                    ### Logistic regression ###
library(ISLR)
?Default
str(Default)
?Default
edit(Default)
logitModel=glm(default~balance,data=Default)
logitModel=glm(default~balance,data=Default,family = binomial)
summary(logitModel)
modelProb=predict(logitModel,type="response")
modelProb
logitModel=glm(default~balance,data=Default,family=binomial)
summary(logitModel)
modelProb=predict(logitModel,type="response")
contrasts(Default$default)
contrasts(Default$default)
modelProb
str(Default)
modelPred=rep("No",10000)
modelPred[modelProb>0.5]="Yes"
table(modelPred,Default$default)
rm(list=ls())                    ### Logistic regression ###
#### Задача 1 ####
# Като изплозвате данните 'Default', конструирайте многомерен логистичен модел за променливата за
# предсказване на променливата 'default'. Коефициентите на кои предиктори в модела са значими?
# Каква е точността на модела? Ако използвате само променливата 'student' като предиктор, как
# може да интерпретирате получения модел?
rm(list=ls())
rm(list=ls())
install.packages("ISLR")
library(ISLR)
str(Default)
?Default
edit(Default)
str(Default)
edit(Default)
logitModel=glm(default~balance+income,data=Default,family=binomial)
logitModel=glm(student~balance+income,data=Default,family=binomial)
summary(model1)
model1=glm(Direction~Lag1+Lag2+Lag3+Lag4+Lag5+Volume,data=Smarket,family=binomial)
summary(model1)
summary(logitModelDefault)
logitModelDefault=glm(default~balance+income,data=Default,family=binomial)
summary(logitModelDefault)
isStudentModel=glm(student~balance+income,data=Default,family=binomial)
summary(isStudentModel)
model1=glm(Direction~Lag1+Lag2+Lag3+Lag4+Lag5+Volume,data=Smarket,family=binomial)
model1Prob=predict(model1,type="response")
model1Prob[1:10]
contrasts(Direction)
contrasts(Direction, data=Smarket)
### Multiple Logistic Regression ###
attach(Smarket)
model1=glm(Direction~Lag1+Lag2+Lag3+Lag4+Lag5+Volume,data=Smarket,family=binomial)
summary(model1)
coef(model1)
summary(model1)$coef
summary(model1)$coef[,4]
model1Prob=predict(model1,type="response")
model1Prob[1:10]
contrasts(Direction, data=Smarket)
contrasts(Direction)
model1Pred=rep("Down",1250)
model1Pred[model1Prob>0.5]="Up"
model1Pred=rep("Down",1250)
model1Pred
model1Pred[model1Prob>0.5]="Up"
table(model1Pred,Direction)
